{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AdamW, AutoConfig, AutoTokenizer\n",
    "from electra_model import ElectraForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "  def __init__(self,\n",
    "               file_path = \"./data/wellness_text_classification.txt\",\n",
    "               num_label = 359,\n",
    "               device = 'cuda',\n",
    "               max_seq_len = 128,\n",
    "               tokenizer = AutoTokenizer.from_pretrained(\"./pretrained_model\")\n",
    "               ):\n",
    "    self.file_path = file_path\n",
    "    self.device = device\n",
    "    self.data = []\n",
    "    self.tokenizer = tokenizer\n",
    "    file = open(self.file_path, 'r')\n",
    "\n",
    "    while True:\n",
    "      line = file.readline()\n",
    "      if not line:\n",
    "        break\n",
    "      datas = line.split(\"    \")\n",
    "      index_of_words = self.tokenizer.encode(datas[0])\n",
    "      token_type_ids = [0] * len(index_of_words)\n",
    "      attention_mask = [1] * len(index_of_words)\n",
    "\n",
    "      padding_length = max_seq_len - len(index_of_words)\n",
    "\n",
    "      index_of_words += [0] * padding_length\n",
    "      token_type_ids += [0] * padding_length\n",
    "      attention_mask += [0] * padding_length\n",
    "\n",
    "      label = int(datas[1][:-1])\n",
    "\n",
    "      data = {\n",
    "              'input_ids': torch.tensor(index_of_words).to(self.device),\n",
    "              'token_type_ids': torch.tensor(token_type_ids).to(self.device),\n",
    "              'attention_mask': torch.tensor(attention_mask).to(self.device),\n",
    "              'labels': torch.tensor(label).to(self.device)\n",
    "             }\n",
    "\n",
    "      self.data.append(data)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self,index):\n",
    "    item = self.data[index]\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader, save_step, finetuned_model, train_step = 0):\n",
    "    losses = []\n",
    "    train_start_index = train_step+1 if train_step != 0 else 0\n",
    "    total_train_step = len(train_loader)\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total= total_train_step, desc=f\"Train({epoch})\") as pbar:\n",
    "        pbar.update(train_step)\n",
    "        for i, data in enumerate(train_loader, train_start_index):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {'input_ids': data['input_ids'],\n",
    "                      'attention_mask': data['attention_mask'],\n",
    "                      'labels': data['labels']\n",
    "                      }\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            loss = outputs[0]\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")\n",
    "\n",
    "            if i >= total_train_step or i % save_step == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss.item(),\n",
    "                    'train_step': i,\n",
    "                    'total_train_step': len(train_loader)\n",
    "                }, finetuned_model)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained_model were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ./pretrained_model and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Train(0):   0%|          | 3/654 [00:30<1:51:54, 10.31s/it, Loss: 5.945 (5.953)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Dev\\Python\\공모전\\ai\\train.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000003?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epoch):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000003?line=46'>47</a>\u001b[0m     epoch \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m offset\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000003?line=47'>48</a>\u001b[0m     loss \u001b[39m=\u001b[39m train( epoch, model, optimizer, train_loader, save_step, finetuned_model, train_step)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000003?line=48'>49</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000003?line=49'>50</a>\u001b[0m     \u001b[39mif\u001b[39;00m loss \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.02\u001b[39m: \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32md:\\Dev\\Python\\공모전\\ai\\train.ipynb Cell 3'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, model, optimizer, train_loader, save_step, finetuned_model, train_step)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=10'>11</a>\u001b[0m inputs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: data[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=11'>12</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: data[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=12'>13</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m: data[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=13'>14</a>\u001b[0m           }\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/train.ipynb#ch0000002?line=18'>19</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Dev\\Python\\공모전\\ai\\electra_model.py:45\u001b[0m, in \u001b[0;36mElectraForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=33'>34</a>\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=34'>35</a>\u001b[0m         input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=42'>43</a>\u001b[0m         output_hidden_states\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=43'>44</a>\u001b[0m ):\n\u001b[1;32m---> <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=44'>45</a>\u001b[0m   discriminator_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melectra(\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=45'>46</a>\u001b[0m     input_ids,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=46'>47</a>\u001b[0m     attention_mask,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=47'>48</a>\u001b[0m     token_type_ids,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=48'>49</a>\u001b[0m     position_ids,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=49'>50</a>\u001b[0m     head_mask,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=50'>51</a>\u001b[0m     inputs_embeds,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=51'>52</a>\u001b[0m     output_attentions,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=52'>53</a>\u001b[0m     output_hidden_states,\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=53'>54</a>\u001b[0m   )\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=55'>56</a>\u001b[0m   sequence_output \u001b[39m=\u001b[39m discriminator_hidden_states[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='file:///d%3A/Dev/Python/%EA%B3%B5%EB%AA%A8%EC%A0%84/ai/electra_model.py?line=56'>57</a>\u001b[0m   logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:916\u001b[0m, in \u001b[0;36mElectraModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=912'>913</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39membeddings_project\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=913'>914</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_project(hidden_states)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=915'>916</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=916'>917</a>\u001b[0m     hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=917'>918</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=918'>919</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=919'>920</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=920'>921</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=921'>922</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=922'>923</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=923'>924</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=924'>925</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=925'>926</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=926'>927</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=928'>929</a>\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:584\u001b[0m, in \u001b[0;36mElectraEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=574'>575</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=575'>576</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=576'>577</a>\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=580'>581</a>\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=581'>582</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=582'>583</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=583'>584</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=584'>585</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=585'>586</a>\u001b[0m         attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=586'>587</a>\u001b[0m         layer_head_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=587'>588</a>\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=588'>589</a>\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=589'>590</a>\u001b[0m         past_key_value,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=590'>591</a>\u001b[0m         output_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=591'>592</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=593'>594</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=594'>595</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:511\u001b[0m, in \u001b[0;36mElectraLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=507'>508</a>\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=508'>509</a>\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=510'>511</a>\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=511'>512</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=512'>513</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=513'>514</a>\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=515'>516</a>\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\modeling_utils.py:2928\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/modeling_utils.py?line=2924'>2925</a>\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/modeling_utils.py?line=2925'>2926</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/modeling_utils.py?line=2927'>2928</a>\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:523\u001b[0m, in \u001b[0;36mElectraLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=521'>522</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=522'>523</a>\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=523'>524</a>\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=524'>525</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\electra\\modeling_electra.py:422\u001b[0m, in \u001b[0;36mElectraIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=420'>421</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=421'>422</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=422'>423</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/transformers/models/electra/modeling_electra.py?line=423'>424</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Administrator/AppData/Local/Programs/Python/Python38/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = f\"./data/wellness_text_classification.txt\"\n",
    "finetuned_model = f\"./finetuned_model/psychological_counseling_model.pth\"\n",
    "pretrained_model = \"./pretrained_model\"\n",
    "\n",
    "\n",
    "n_epoch = 100\n",
    "batch_size = 16\n",
    "ctx = \"cuda\"\n",
    "device = torch.device(ctx)\n",
    "save_step = 1000\n",
    "learning_rate = 5e-6 \n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "dataset = TextClassificationDataset(file_path=data, tokenizer=tokenizer, device=device)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "electra_config = AutoConfig.from_pretrained(pretrained_model)\n",
    "model = ElectraForSequenceClassification.from_pretrained(pretrained_model_name_or_path=pretrained_model,\n",
    "                                                            config=electra_config,\n",
    "                                                            num_labels=359)\n",
    "model.to(device)\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "      'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "\n",
    "pre_epoch, pre_loss, train_step = 0, 0, 0\n",
    "if os.path.isfile(finetuned_model):\n",
    "    checkpoint = torch.load(finetuned_model, map_location=device)\n",
    "    pre_epoch = checkpoint['epoch']\n",
    "    pre_loss = checkpoint['loss']\n",
    "    train_step =  checkpoint['train_step']\n",
    "    total_train_step =  checkpoint['total_train_step']\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    print(f\"load pretrain from: {finetuned_model}, epoch={pre_epoch}, loss={pre_loss}\")\n",
    "\n",
    "losses = []\n",
    "offset = pre_epoch\n",
    "for step in range(n_epoch):\n",
    "    epoch = step + offset\n",
    "    loss = train( epoch, model, optimizer, train_loader, save_step, finetuned_model, train_step)\n",
    "    losses.append(loss)\n",
    "    if loss <= 0.02: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.705697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.484714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.322536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.090330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.845945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.023602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.020716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.027723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.023979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.018600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss\n",
       "0   5.705697\n",
       "1   5.484714\n",
       "2   5.322536\n",
       "3   5.090330\n",
       "4   4.845945\n",
       "..       ...\n",
       "62  0.023602\n",
       "63  0.020716\n",
       "64  0.027723\n",
       "65  0.023979\n",
       "66  0.018600\n",
       "\n",
       "[67 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\"loss\": losses}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "display(df)\n",
    "plt.figure(figsize=[12, 8])\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "plt.savefig('./Epoch_Loss_data.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7be44ff6d022abcdd56ca5d84b9c7c57bcc1116775f704a69faf25b23490917"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
